training:
  learning_rate: 0.0005
  batch_size: 64
  epochs: 50
model:
  input_size: 784
  layer2_size: 512
  layer3_size: 256
  layer4_size: 128
  num_classes: 10
  dropout: 0.2
